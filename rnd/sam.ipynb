{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791fe8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5582568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-07 18:50:10--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2600:9000:2105:9e00:13:6e38:acc0:93a1, 2600:9000:2105:ae00:13:6e38:acc0:93a1, 2600:9000:2105:c000:13:6e38:acc0:93a1, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2600:9000:2105:9e00:13:6e38:acc0:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
      "Saving to: ‘sam_vit_h_4b8939.pth’\n",
      "\n",
      "sam_vit_h_4b8939.pt 100%[===================>]   2.39G  39.0MB/s    in 71s     \n",
      "\n",
      "2025-08-07 18:51:21 (34.5 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7edfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"dataset\"     # folder with your images\n",
    "CROPS_DIR = \"crops_for_labeling\"     # where crops will be saved\n",
    "YOLO_LABELS_DIR = \"yolo_labels\"      # YOLO label txt files\n",
    "SAM_CHECKPOINT = \"sam_vit_h_4b8939.pth\"  # path to SAM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca7adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(CROPS_DIR, exist_ok=True)\n",
    "os.makedirs(YOLO_LABELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584f6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"  # or \"cuda\" if on GPU\n",
    "\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=SAM_CHECKPOINT)\n",
    "sam.to(device=device)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfabd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [34:35<00:00, 138.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crops ready for labeling! Fill in the 'label' column in crops_to_label.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crops_data = []\n",
    "\n",
    "for img_file in tqdm(os.listdir(IMAGES_DIR)):\n",
    "    if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "    img_path = os.path.join(IMAGES_DIR, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    masks = mask_generator.generate(img_rgb)\n",
    "\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    H, W = img_pil.size\n",
    "\n",
    "    for i, mask_dict in enumerate(masks):\n",
    "        mask = mask_dict['segmentation']\n",
    "        y_idx, x_idx = np.where(mask)\n",
    "        if len(x_idx) == 0 or len(y_idx) == 0:\n",
    "            continue\n",
    "        x_min, x_max = x_idx.min(), x_idx.max()\n",
    "        y_min, y_max = y_idx.min(), y_idx.max()\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "        # Save crop for labeling\n",
    "        crop = img_pil.crop(bbox)\n",
    "        crop_filename = f\"{os.path.splitext(img_file)[0]}_obj{i+1}.jpg\"\n",
    "        crop_path = os.path.join(CROPS_DIR, crop_filename)\n",
    "        crop.save(crop_path)\n",
    "\n",
    "        # Record for labeling\n",
    "        crops_data.append({\n",
    "            \"image_file\": img_file,\n",
    "            \"crop_file\": crop_filename,\n",
    "            \"bbox_x1\": x_min, \"bbox_y1\": y_min, \"bbox_x2\": x_max, \"bbox_y2\": y_max,\n",
    "            \"img_w\": W, \"img_h\": H,\n",
    "            \"label\": \"\",      # <--- Fill this after labeling (manual or with LLM)\n",
    "        })\n",
    "\n",
    "# Save all crops to a CSV for fast labeling\n",
    "df = pd.DataFrame(crops_data)\n",
    "df.to_csv(\"rnd/crops_to_label.csv\", index=False)\n",
    "print(\"Crops ready for labeling! Fill in the 'label' column in crops_to_label.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
